ggplot(data = .,
aes(x = Var2,
y = Var1)) +
geom_raster(aes(fill = value)) +
scale_fill_grey(name = "",
labels = c("Present","Missing")) +
theme_minimal() +
theme(axis.text.x  = element_text(angle=45, vjust=0.5)) +
labs(x = "Variables in Dataset",
y = "Rows / observations",
title = "Missing Values in Dataset")
# define the URL -- you could dynamically build this
URL <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls"
# download file
download.file(URL, destfile="Data_Cortex_Nuclear.xls")
# load the file
ncortex.raw <- as.data.frame(read_excel("Data_Cortex_Nuclear.xls"))
head(ncortex.raw)
dim(ncortex.raw)
str(ncortex.raw)
#check for missing values
ncortex.raw %>%
is.na %>%
melt %>%
ggplot(data = .,
aes(x = Var2,
y = Var1)) +
geom_raster(aes(fill = value)) +
scale_fill_grey(name = "",
labels = c("Present","Missing")) +
theme_minimal() +
theme(axis.text.x  = element_text(angle=45, vjust=0.5)) +
labs(x = "Variables in Dataset",
y = "Rows / observations",
title = "Missing Values in Dataset")
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# We have the numeric features (77) and a multiclass target variable (1)
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# We have the numeric features (77) and a multiclass target variable (1)
head(ncortex)
## imputing missing values
# remove missing values with means by each group
ncortex <- ncortex %>%
group_by(class) %>%
mutate_each(funs(replace(., which(is.na(.)), mean(., na.rm=TRUE)))) %>%
as.data.frame()
# check basic statistics
summary(ncortex)
proteins <- names(Data[2:78]) #creating list of protein names
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# We have the numeric features (77) and a multi-class target variable (1)
proteins <- names(ncortex[2:78]) #creating list of protein names
proteins
classes <- as.vector(unique(as.character(ncortex$class))) #creating list of classes names
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# We have the numeric features (77) and a multi-class target variable (1)
head(ncortex)
proteins <- names(ncortex[2:78]) #creating list of protein names
proteins
classes <- as.vector(unique(as.character(ncortex$class))) #creating list of classes names
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# We have the numeric features (77) and a multi-class target variable (1)
head(ncortex)
proteins <- names(ncortex[1:77]) #creating list of protein names
proteins
classes <- as.vector(unique(as.character(ncortex$class))) #creating list of classes names
classes
# We have the numeric features (77) and a multi-class target variable (1)
head(ncortex, 3)
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# We have the numeric features (77) and a multi-class target variable (1)
head(ncortex, 3)
proteins <- names(ncortex[1:77]) #creating list of protein names
classes <- as.vector(unique(as.character(ncortex$class))) #creating list of classes names
for(i in 1:length(proteins)){
plot <- ggplot(ncortex, aes(eval(parse(text = proteins[i])))) +
geom_histogram(aes(fill=..count..), color = "black", alpha = 0.5) +
scale_fill_gradient("Count", low="green", high="red") +
labs(title = proteins[i],
x = "Expression Level",
y = "Count") +
theme_light()
cat("#### ", proteins[i], "\n")
print(plot)
cat('\n\n')
}
ggplot(Data, aes(x = eval(parse(text = proteins[1])))) +
geom_histogram(aes(fill=..count..), color = "black", alpha = 0.5) +
scale_fill_gradient("Count", low="green", high="red") +
labs(title = proteins[1],
x = "Expression Level",
y = "Count")
for(i in 1:length(proteins)){
plot <- ggplot(ncortex, aes(eval(parse(text = proteins[i])))) +
geom_histogram(aes(fill=..count..), color = "black", alpha = 0.5) +
scale_fill_gradient("Count", low="green", high="red") +
labs(title = proteins[i],
x = "Expression Level",
y = "Count") +
theme_light()
cat("#### ", proteins[i], "\n")
print(plot)
cat('\n\n')
}
ggplot(ncortex, aes(x = eval(parse(text = proteins[1])))) +
geom_histogram(aes(fill=..count..), color = "black", alpha = 0.5) +
scale_fill_gradient("Count", low="green", high="red") +
labs(title = proteins[1],
x = "Expression Level",
y = "Count")
for(i in 1:length(proteins)){
plot <- ggplot(Data, aes(x = class, y = eval(parse(text = proteins[i])))) +
geom_boxplot(aes(fill = class), alpha = 0.7) +
stat_summary(fun.y=mean, colour="darkred", geom="point", size=2) +
labs(y = proteins[i]) +
theme_light()
cat("#### ", proteins[i], "\n")
print(plot)
cat('\n\n')
}
for(i in 1:length(proteins)){
plot <- ggplot(ncortex, aes(x = class, y = eval(parse(text = proteins[i])))) +
geom_boxplot(aes(fill = class), alpha = 0.7) +
stat_summary(fun.y=mean, colour="darkred", geom="point", size=2) +
labs(y = proteins[i]) +
theme_light()
cat("#### ", proteins[i], "\n")
print(plot)
cat('\n\n')
}
# Min-max scaling (range 0-1 for each column)
nc.feat <- ncortex[1:77]
min_max_scaling <- function(data) {
pp <- preProcess(data.frame(data), method=c("range"))
scaled.nc <- predict(pp, as.data.frame(data))
return(scaled.nc)
}
scaled_ncortex <- min_max_scaling(data=nc.feat)
# check normality distribution using Shapiro-wilk test
testNormality <- function(data) {
norm.res <- data.frame(do.call(
cbind, lapply(data, function(x) shapiro.test(x)["p.value"])))
unnorm.col <- list(which(norm.res > 0.05))
print(paste("The unnormalized column(s) present in the data are", unnorm.col))
return(unlist(unnorm.col))
}
# check our scaled data for any unnormalized column(s)
colX <- testNormality(data = scaled_ncortex)
# check the distribution curves for the above columns
pairs.panels(scaled_ncortex[,colX])
##########################################
########## Feature Engineering ###########
##########################################
nc.Class <- ncortex[78]
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
# visualize the matrix, clustering features by correlation index
corrplot(corMatNC1, order = "hclust")
nc.Class <- ncortex[78]
nc.Class
scaled_ncortex
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
# visualize the matrix, clustering features by correlation index
corrplot(corMatNC1, order = "hclust")
## Method -2: Variable Importance
feat <- reduced_data
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
# visualize the matrix, clustering features by correlation index
corrplot(corMatNC1)
# After inspecting the matrix, we set the correlation threshold at 0.75
# Apply correlation filter at 0.75
highlyCor <- findCorrelation(corMatNC1, 0.75)
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
# visualize the matrix, clustering features by correlation index
corrplot(corMatNC1, order = "hclust")
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
corMatNC1
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
#corMatNC1 <- cor(rawData)
rawData
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
#corMatNC1 <- cor(rawData)
cor(rawData)
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
## Method -2: Variable Importance
feat <- norm_ncortex
feat$Class <- nc.Class
# training `randomForest` to calculate feature importance
rf  <- randomForest(Class ~., data = feat)
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# We have the numeric features (77) and a multi-class target variable (1)
ncortex$class <- as.factor(ncortex.raw$class)
proteins <- names(ncortex[1:77]) #creating list of protein names
classes <- ncortex$class
# remove missing values with means of each group
ncortex <- ncortex %>%
group_by(class) %>%
mutate_each(funs(replace(., which(is.na(.)), mean(., na.rm=TRUE)))) %>%
as.data.frame()
# check basic statistics
summary(ncortex)
for(i in 1:length(proteins)){
plot <- ggplot(ncortex, aes(eval(parse(text = proteins[i])))) +
geom_histogram(aes(fill=..count..), color = "black", alpha = 0.5) +
scale_fill_gradient("Count", low="green", high="red") +
labs(title = proteins[i],
x = "Expression Level",
y = "Count") +
theme_light()
cat("#### ", proteins[i], "\n")
print(plot)
cat('\n\n')
}
ggplot(ncortex, aes(x = eval(parse(text = proteins[1])))) +
geom_histogram(aes(fill=..count..), color = "black", alpha = 0.5) +
scale_fill_gradient("Count", low="green", high="red") +
labs(title = proteins[1],
x = "Expression Level",
y = "Count")
##########################################
########## Feature Engineering ###########
##########################################
nc.Class <- classes
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
# visualize the matrix, clustering features by correlation index
corrplot(corMatNC1, order = "hclust")
knitr::opts_chunk$set(echo = TRUE)
packages <- c("readxl", "tidyverse", "psych", "corrplot", "randomForest",
"e1071", "caret", "neuralnet", "nnet", "NeuralSens","ipred",
"DataExplorer", "ggplot2", "FactoMineR", "factoextra", "devtools",
"ggbiplot", "pROC")
# readxl: for reading excel data file
# tidyverse: for general data utility functions
# psych: for pairs panel plot
# corrplot: for correlation matrix
# e1071: for Naive Bayes
# caret: for data preparation and evaluation of model
# neuralnet: for NN modeling
# nnet: for multinomial logistic regression
# ipred: for bagging
# randomForest: for stacked learner and variable importance
# DataExplorer and ggplot2: for plots
# FactoMineR, factoextra, devtools, ggbiplot: for PCA plots
# pROC: for ROC and AUC plot
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
# define the URL -- you could dynamically build this
URL <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls"
# download file
download.file(URL, destfile="Data_Cortex_Nuclear.xls")
# load the file
ncortex.raw <- as.data.frame(read_excel("Data_Cortex_Nuclear.xls"))
head(ncortex.raw)
dim(ncortex.raw)
str(ncortex.raw)
# turning "warnings" off
options(warn=-1)
# since we are focusing our analysis on the `class` variable, we are going to drop
# the rest of the categorical variables from the dataNC along with the `MouseID`column
ncortex <- subset(ncortex.raw, select = -c(MouseID, Behavior, Genotype, Treatment))
# We have the numeric features (77) and a multiclass target variable (1)
# factorize target variable
ncortex$class <- as.factor(ncortex.raw$class)
# check categorical distribution
plot_bar(ncortex)
## imputing missing values
# check the columns with NAs
featNA <- names(which(sapply(ncortex, anyNA)))
dataNA <- ncortex[, featNA]
# total number of NAs
sum(is.na(dataNA))
# check the distribution of NAs in each column
colSums(is.na(dataNA))
# all columns have NAs below 50% of the sample size. Hence, they can be imputed.
# computing mean of all columns using colMeans()
means <- colMeans(dataNA, na.rm = TRUE)
# replacing NA with mean value of each column
for(i in colnames(dataNA)){
dataNA[,i][is.na(dataNA[,i])] <- means[i]
}
# check missing values in our feature dataNC frame
sum(is.na(dataNA))
# replace the imputed features with the original dataNC
ncortex[,featNA] <- dataNA
# get numeric feature
nc.feat <- ncortex[,-ncol(ncortex)]
# get target variables
nc.Class <- ncortex$class
# check basic statistics
summary(ncortex)
# Min-max scaling (range 0-1 for each column)
min_max_scaling <- function(data) {
pp <- preProcess(data.frame(data), method=c("range"))
scaled.nc <- predict(pp, as.data.frame(data))
return(scaled.nc)
}
scaled_ncortex <- min_max_scaling(data=nc.feat)
# check normality distribution using Shapiro-wilk test
testNormality <- function(data) {
norm.res <- data.frame(do.call(
cbind, lapply(data, function(x) shapiro.test(x)["p.value"])))
unnorm.col <- list(which(norm.res > 0.05))
print(paste("The unnormalized column(s) present in the data are", unnorm.col))
return(unlist(unnorm.col))
}
# check our scaled data for any unnormalized column(s)
colX <- testNormality(data = scaled_ncortex)
# check the distribution curves for the above columns
pairs.panels(scaled_ncortex[,colX])
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
# visualize the matrix, clustering features by correlation index
corrplot(corMatNC1, order = "hclust")
# After inspecting the matrix, we set the correlation threshold at 0.75
# Apply correlation filter at 0.75
highlyCor <- findCorrelation(corMatNC1, 0.75)
#then we remove all the variable correlated with more 0.75.
reduced_data <- rawData[,-highlyCor]
# check the effect of correlation cut-off filter
corMatNC2 <- cor(reduced_data)
corrplot(corMatNC2, order = "hclust")
# check the columns with NAs
featNA <- names(which(sapply(ncortex, anyNA)))
dataNA <- ncortex[, featNA]
# total number of NAs
sum(is.na(dataNA))
# check the distribution of NAs in each column
colSums(is.na(dataNA))
# all columns have NAs below 50% of the sample size. Hence, they can be imputed.
# computing mean of all columns using colMeans()
means <- colMeans(dataNA, na.rm = TRUE)
# replacing NA with mean value of each column
for(i in colnames(dataNA)){
dataNA[,i][is.na(dataNA[,i])] <- means[i]
}
# check missing values in our feature dataNC frame
sum(is.na(dataNA))
# replace the imputed features with the original dataNC
ncortex[,featNA] <- dataNA
# get numeric feature
nc.feat <- ncortex[,-ncol(ncortex)]
# get target variables
nc.Class <- ncortex$class
# check basic statistics
summary(ncortex)
for(i in 1:length(proteins)){
plot <- ggplot(ncortex, aes(eval(parse(text = proteins[i])))) +
geom_histogram(aes(fill=..count..), color = "black", alpha = 0.5) +
scale_fill_gradient("Count", low="green", high="red") +
labs(title = proteins[i],
x = "Expression Level",
y = "Count") +
theme_light()
cat("#### ", proteins[i], "\n")
print(plot)
cat('\n\n')
}
# Min-max scaling (range 0-1 for each column)
nc.feat <- ncortex[1:77]
min_max_scaling <- function(data) {
pp <- preProcess(data.frame(data), method=c("range"))
scaled.nc <- predict(pp, as.data.frame(data))
return(scaled.nc)
}
scaled_ncortex <- min_max_scaling(data=nc.feat)
# check normality distribution using Shapiro-wilk test
testNormality <- function(data) {
norm.res <- data.frame(do.call(
cbind, lapply(data, function(x) shapiro.test(x)["p.value"])))
unnorm.col <- list(which(norm.res > 0.05))
print(paste("The unnormalized column(s) present in the data are", unnorm.col))
return(unlist(unnorm.col))
}
# check our scaled data for any unnormalized column(s)
colX <- testNormality(data = scaled_ncortex)
# check the distribution curves for the above columns
pairs.panels(scaled_ncortex[,colX])
##########################################
########## Feature Engineering ###########
##########################################
# All columns are normally distributed
norm_ncortex <- scaled_ncortex
norm_ncortex$Class <- nc.Class
head(norm_ncortex)
dim(norm_ncortex)
## Method-1: Correlation Cut-off
rawData <- scaled_ncortex
# compute the correlation matrix
corMatNC1 <- cor(rawData)
# visualize the matrix, clustering features by correlation index
corrplot(corMatNC1, order = "hclust")
# After inspecting the matrix, we set the correlation threshold at 0.75
# Apply correlation filter at 0.75
highlyCor <- findCorrelation(corMatNC1, 0.75)
#then we remove all the variable correlated with more 0.75.
reduced_data <- rawData[,-highlyCor]
# check the effect of correlation cut-off filter
corMatNC2 <- cor(reduced_data)
corrplot(corMatNC2, order = "hclust")
